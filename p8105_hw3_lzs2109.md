Data Science I Homework 3 - lzs2109
================
Louis Sharp
10/12/2021

### **Problem 1**

``` r
library(tidyverse)
library(p8105.datasets)
data("instacart")
```

Insert paragraph describing dataset

``` r
instacart %>% 
  group_by(aisle) %>% 
  summarize(n_obs = n()) %>% 
  arrange(desc(n_obs))
```

    ## # A tibble: 134 × 2
    ##    aisle                          n_obs
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # … with 124 more rows

There are 134 different aisles in the dataset, with over 150,000 items
ordered from both the fresh vegetables and fresh fruits aisles. The next
most ordered from aisle is the packaged vegetables fruits aisle with
almost 78,500 items being ordered from it.

Now, here’s a plot showing the number of items ordered in each aisle,
with only aisles with over 10,000 items included.

``` r
instacart %>% 
  group_by(aisle) %>% 
  summarize(n_obs = n()) %>% 
  filter(n_obs > 10000) %>% 
  ggplot(aes(y = aisle, x = n_obs)) + 
  geom_point()
```

![](p8105_hw3_lzs2109_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

Next, we’ll look at the top 3 most popular items from the aisles “baking
ingredients”, “dog food care”, and “packaged vegetables fruits”.

``` r
instacart %>% 
  filter(aisle == c("baking ingredients",
                    "dog food care",
                    "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(n_obs = n()) %>% 
  mutate(product_rank = min_rank(desc(n_obs))) %>% 
  filter(product_rank < 4) %>% 
  knitr::kable()
```

    ## `summarise()` has grouped output by 'aisle'. You can override using the `.groups` argument.

| aisle                      | product\_name                                   | n\_obs | product\_rank |
|:---------------------------|:------------------------------------------------|-------:|--------------:|
| baking ingredients         | Light Brown Sugar                               |    157 |             1 |
| baking ingredients         | Organic Vanilla Extract                         |    122 |             3 |
| baking ingredients         | Pure Baking Soda                                |    140 |             2 |
| dog food care              | Organix Chicken & Brown Rice Recipe             |     13 |             2 |
| dog food care              | Organix Grain Free Chicken & Vegetable Dog Food |     14 |             1 |
| dog food care              | Original Dry Dog                                |      9 |             3 |
| packaged vegetables fruits | Organic Baby Spinach                            |   3324 |             1 |
| packaged vegetables fruits | Organic Blueberries                             |   1692 |             3 |
| packaged vegetables fruits | Organic Raspberries                             |   1920 |             2 |

Next, let’s explore what mean hour of the day Pink Lady Apples and
Coffee Ice Cream are ordered on each day of the week, with a column for
each day of the week and a row for each of the two items.

``` r
instacart %>% 
  select(order_hour_of_day, order_dow, product_name) %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(names_from = order_dow, values_from = mean_hour) %>% 
  knitr::kable()
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the `.groups` argument.

| product\_name    |        0 |        1 |        2 |        3 |        4 |        5 |        6 |
|:-----------------|---------:|---------:|---------:|---------:|---------:|---------:|---------:|
| Coffee Ice Cream | 13.77419 | 14.31579 | 15.38095 | 15.31818 | 15.21739 | 12.26316 | 13.83333 |
| Pink Lady Apples | 13.44118 | 11.36000 | 11.70213 | 14.25000 | 11.55172 | 12.78431 | 11.93750 |

### **Problem 2**

``` r
data("brfss_smart2010")

brfss_smart2010 = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr,
         county = locationdesc,
         resp_id = respid) %>% 
  filter(topic == "Overall Health") %>% 
  mutate(response = factor(response, 
                           ordered = TRUE, 
                           levels = c("Poor", "Fair", "Good", "Very good", "Excellent")))

#filtering by "Overall Health" seems to have eliminated all responses other
#than those from Poor to Excellent, so no additional code for that is needed.
```

For the years 2002 and 2010, we want to determine which states were
observed at 7 or more locations, renamed to “county” in this dataset.
Below, we’ll investigate that.

``` r
brfss_smart2010 %>% 
  filter(year == 2002) %>% 
  select(year, state, county) %>% 
  group_by(year, state) %>% 
  distinct() %>% 
  summarize(n_county = n()) %>% 
  filter(n_county > 6)
```

    ## `summarise()` has grouped output by 'year'. You can override using the `.groups` argument.

    ## # A tibble: 6 × 3
    ## # Groups:   year [1]
    ##    year state n_county
    ##   <int> <chr>    <int>
    ## 1  2002 CT           7
    ## 2  2002 FL           7
    ## 3  2002 MA           8
    ## 4  2002 NC           7
    ## 5  2002 NJ           8
    ## 6  2002 PA          10

It looks like in 2002, only six states were observed at 7 or more
locations or counties. These states included Connecticut (7 counties),
Florida (7 counties), Massachusets (8 counties), North Carolina (7
counties), New Jersey (8 counties), and Pennsylvania (10 counties). None
were observed at more than 10 counties or locations.

``` r
brfss_smart2010 %>% 
  filter(year == 2010) %>% 
  select(year, state, county) %>% 
  group_by(year, state) %>% 
  distinct() %>% 
  summarize(n_county = n()) %>% 
  filter(n_county > 6)
```

    ## `summarise()` has grouped output by 'year'. You can override using the `.groups` argument.

    ## # A tibble: 14 × 3
    ## # Groups:   year [1]
    ##     year state n_county
    ##    <int> <chr>    <int>
    ##  1  2010 CA          12
    ##  2  2010 CO           7
    ##  3  2010 FL          41
    ##  4  2010 MA           9
    ##  5  2010 MD          12
    ##  6  2010 NC          12
    ##  7  2010 NE          10
    ##  8  2010 NJ          19
    ##  9  2010 NY           9
    ## 10  2010 OH           8
    ## 11  2010 PA           7
    ## 12  2010 SC           7
    ## 13  2010 TX          16
    ## 14  2010 WA          10

By 2010, fourteen different states were observed at 7 or more locations.
These states include five of the six from 2002 (no Connecticut), as well
as California, Colorado, Maryland, Nebraska, New York, Ohio, South
Carolina, Texas, and Washington.

``` r
brfss_smart2010 %>% 
  filter(response == "Excellent") %>% 
  select(year, state, county, data_value) %>% 
  group_by(year, state, county) %>% 
  summarize(mean_data_value = mean(data_value)) %>% 
  ggplot(aes(x = year, y = mean_data_value, color = state)) +
  geom_line()
```

    ## `summarise()` has grouped output by 'year', 'state'. You can override using the `.groups` argument.

![](p8105_hw3_lzs2109_files/figure-gfm/unnamed-chunk-9-1.png)<!-- -->

``` r
brfss_smart2010 %>% 
  filter(state == "NY",
         year == 2006 | year == 2010) %>% 
  select(year, state, county, response, data_value) %>% 
  ggplot(aes(x = response, y = data_value, color = county)) + 
  geom_boxplot() +
  facet_grid(. ~ year)
```

![](p8105_hw3_lzs2109_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

### **Problem 3**

``` r
accel_df = read_csv("data/accel_data.csv") %>% 
  janitor::clean_names()
```

    ## Rows: 35 Columns: 1443

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
